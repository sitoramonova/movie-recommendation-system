# movie-recommendation-system
![Image alt](https://github.com/sitoramonova/movie-recommendation-system/blob/main/%D0%B4%D0%B8%20%D0%BA%D0%B0%D0%BF%D1%80%D0%B8%D0%BE.png)

Этот проект предоставляет помощь киноманам, которые иногда сталкиваются с трудностями при выборе фильма для просмотра. Он предлагает удобную и простую в использовании функцию, которая позволяет пользователю ввести название своего любимого фильма, а затем автоматически генерирует список из 30 названий фильмов, которые должны понравиться этому пользователю.
Учитывается несколько ключевых факторов: «жанры», «ключевые слова», «слоган», «актеры», «режиссер». Благодаря этому у пользователя появляется возможность обнаружить новые фильмы, которые соответствуют его вкусам и предпочтениям. <br/>

Здесь используется датасет из 4803 фильмов который можно скачать по ссылке: https://drive.google.com/file/d/1cCkwiVv4mgfl20ntgY3n4yApcWqqZQe6/view<br/>
В нем содержатся следующие данные о фильмах: index, budget, genres, homepage, id, keywords, original_languag,e original_title, overview, popularity, production_companies, production_countries, release_date, revenue, 
runtime, spoken_languages, status, tagline, title, vote_average, vote_count, cast, crew director. <br/>

В работе выбирается 5 колонок из этого датасета: 'genres','keywords','tagline','cast','director', комбинируем значения этих колонок для каждого фильма, тем самым, получаем масси из строк, где каждая строка - это название фильма, его жанр, ключевые слова, слоган, актеры, режиссер, записанные через пробел.<br/>

Далее, преобразуем текстовых данные( массив combined_features) в векторы с помощью TfidfVectorizer().<br/>

Теперь, получив значение feature_vectors необходимо оценить их сходства, исходя из этого мы получим на вход название фильма, а на выход - список фильмов, которые похожи на данный.
Существует несколько видов сравнения: <br/>
## 1. Наибольшая общая подпоследовательность
1. Наибольшая общая подпоследовательность (LCS, longest common subsequence) - набор подстрок, входящих в обе строки в одинаковом
порядке. Мы разрешаем подпоследовательности состоять только их целых слов. Для получения меры сходства из наибольшей
общей подпоследовательности достаточно взять отношение удвоенного
количества слов в ней к сумме слов в обеих строках:<br/>
$similarityLCS(s1, s2) = \frac{2 \cdot |LCS(s1, s2)} {|s1| + |s2|}$<br/>
В данной работе для нахождения наибольшей общей подпоследовательности использована реализация алгоритма из библиотеки difflib<br/>
## 2. Косинусное расстояние<br/>
Косинусное расстояние (COS, cosine similarity) измеряет сходство
между текстами как косинус угла между их векторными представлениями <br/>
$similarityCOS(s1, s2) = \frac{\overline{s1} \cdot \overline{s2} }{||\overline{s1}|| \cdot ||\overline{s2}||}$ <br/>

Реализация алгоритма вычисления косинуса между векторными представлениями взята из библиотеки sklearn.metrics.pairwise.<br/>
## 3. Locality-Sensitive Hashing <br/>
Locality-sensitive hashing (LSH — вероятностный метод понижения размерности многомерных данных. Основная идея состоит в таком подборе хеш-функций для некоторых измерений, чтобы похожие объекты с высокой степенью вероятности попадали в одну корзину. Один из способов борьбы с «проклятием размерности» при поиске и анализе многомерных данных, которое заключается в том, что при росте размерности исходных данных поиск по индексу ведёт себя хуже, чем последовательный просмотр. Метод позволяет строить структуру для быстрого приближённого (вероятностного) поиска n-мерных векторов, «похожих» на искомый шаблон.

LSH является одним из наиболее популярных на сегодняшний день приближённых алгоритмов поиска ближайших соседей (Approximate Nearest Neighbor, ANN). LSH в этом подходе отображает множество точек в высокоразмерном пространстве в множество ячеек, т. е. в хеш-таблицу. В отличие от традиционных хешей, LSH обладает свойством чувствительности к местоположению (locality-sensitive hash), благодаря чему способен помещать соседние точки в одну и ту же ячейку.<br/>
## 4.Расстояние Левенштейна <br/>
Расстояние Левенштейна (LEV, Levenshtein distance) — это минимальное количество вставок, удалений и замен символов, необходимых
для преобразования одной строки в другую . Для преобразования
расстояния в меру сходства надо нормализовать его максимально возможным значением — максимумом длин двух строк — и вычесть из 1.
Это же значение можно получить из отношения длины наибольшей
общей подпоследовательности к максимуму длин строк <br/>
$similarityLEV (s1, s2) = 1 − \frac {LEV (s1, s2)} {max(|s1|, |s2|)} = \frac{LCS(s1, s2)}{max(|s1|, |s2|)}$ <br/>

Для вычисления расстояния Левенштейна используется алгоритм поиска наибольшей общей подпоследовательности из
библиотеки difflib.<br/>

В нашем случае, мы сравниваем данные с помощью cosine similarity. Получаем массив , сортируем его и выводим значения, т.е названия фильмов, которые больше всего похожи на данный фильм, учитывая наш запрос. <br/>

Теперь, давайте немного изменим наш запрос. Не будем учитывать режиссеров фильма, но учтем рейтинг и дату выхода. и посмотрим, как изменится вывод.<br/> 
![Image alt](https://github.com/sitoramonova/movie-recommendation-system/blob/main/%D0%B4%D0%B8%20%D0%BA%D0%B0%D0%BF%D1%80%D0%B8%D0%BE.png)





